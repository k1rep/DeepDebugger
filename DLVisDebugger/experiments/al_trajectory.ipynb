{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from scipy.special import softmax\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.data import ActiveLearningDataProvider\n",
    "from singleVis.projector import TimeVisProjector,tfDVIProjector\n",
    "from singleVis.trajectory_manager import Recommender"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "# read results\n",
    "import pandas as pd\n",
    "eval_path = \"/home/xianglin/projects/DVI_data/active_learning/random/resnet18/feedback.xlsx\"\n",
    "col = np.array([\"task\", \"dataset\", \"method\", \"rate\", \"tolerance\", \"iter\", \"eval\"])\n",
    "df = pd.read_excel(eval_path, index_col=0, dtype={\"task\":str, \"dataset\":str, \"method\":str, \"rate\":int, \"tolerance\":float, \"iter\":int, \"eval\":float})"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "df[(df.task == \"RA_M\")&(df.dataset==\"cifar10\")&(df.method==\"TimeVis\")&(df.rate==30)&(df.iter==3)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "DATASET = \"MNIST\"\n",
    "RATE = \"10\"\n",
    "VIS_METHOD = \"TimeVis\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "CONTENT_PATH = \"/home/xianglin/projects/DVI_data/active_learning/random/resnet18/{}/{}\".format(DATASET, RATE)\n",
    "sys.path.append(CONTENT_PATH)\n",
    "with open(os.path.join(CONTENT_PATH, \"config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = config[VIS_METHOD]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "CLASSES = config[\"CLASSES\"]\n",
    "GPU_ID = config[\"GPU\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "# embedding trajectories\n",
    "TOTOAL_EPOCH = (EPOCH_END-EPOCH_START)//EPOCH_PERIOD + 1\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "ENCODER_DIMS = VISUALIZATION_PARAMETER[\"ENCODER_DIMS\"]\n",
    "DECODER_DIMS = VISUALIZATION_PARAMETER[\"DECODER_DIMS\"]\n",
    "VIS_MODEL_NAME = VISUALIZATION_PARAMETER[\"VIS_MODEL_NAME\"]\n",
    "\n",
    "# define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import Model.model as subject_model\n",
    "net = eval(\"subject_model.{}()\".format(NET))\n",
    "data_provider = ActiveLearningDataProvider(CONTENT_PATH, net, EPOCH_START,device=DEVICE, classes=CLASSES, iteration_name=\"Epoch\")\n",
    "\n",
    "if VIS_METHOD == \"DVI\":\n",
    "    # Define Projector\n",
    "    flag = \"_temporal_id_withoutB\"\n",
    "    projector = tfDVIProjector(CONTENT_PATH, flag=flag)\n",
    "elif VIS_METHOD == \"TimeVis\":\n",
    "    model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "    projector = TimeVisProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, device=DEVICE)\n",
    "else:\n",
    "    raise NotImplementedError"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# uncertainty\n",
    "samples = data_provider.train_representation_all(EPOCH_END)\n",
    "pred = data_provider.get_pred(EPOCH_END, samples)\n",
    "confidence = np.amax(softmax(pred, axis=1), axis=1)\n",
    "uncertainty = 1-confidence"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "samples = np.zeros((TOTOAL_EPOCH, LEN, 512))\n",
    "for i in range(EPOCH_START, EPOCH_END, EPOCH_PERIOD):\n",
    "    e = (i-EPOCH_START)//EPOCH_PERIOD\n",
    "    samples[e] = data_provider.train_representation_all(i)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "embeddings_2d = np.zeros((TOTOAL_EPOCH, LEN, 2))\n",
    "for i in range(EPOCH_START, EPOCH_END, EPOCH_PERIOD):\n",
    "    e = (i-EPOCH_START)//EPOCH_PERIOD\n",
    "    embeddings_2d[e] = projector.batch_project(i, samples[e])\n",
    "embeddings_2d = np.transpose(embeddings_2d, [1,0,2])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "path = os.path.join(CONTENT_PATH, \"Model\", \"{}_trajectory_embeddings.npy\".format(VIS_METHOD))\n",
    "np.save(path,embeddings_2d)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "path = os.path.join(CONTENT_PATH, \"Model\", \"{}_trajectory_embeddings.npy\".format(VIS_METHOD))\n",
    "embeddings_2d = np.load(path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "samples.shape,uncertainty.shape, embeddings_2d.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "labels = data_provider.train_labels_all(EPOCH_END)\n",
    "# remove label data\n",
    "lb_idxs = data_provider.get_labeled_idx(EPOCH_END)\n",
    "ulb_idxs = data_provider.get_unlabeled_idx(LEN, lb_idxs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "ulb_uncertainty = uncertainty[ulb_idxs]\n",
    "ulb_trajectory = embeddings_2d[ulb_idxs]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import time\n",
    "import pickle\n",
    "t_start = time.time()\n",
    "tm = Recommender(ulb_uncertainty, ulb_trajectory, cls_num=30, period=15, metric=\"a\")\n",
    "tm.clustered()\n",
    "t_end = time.time()\n",
    "with open(os.path.join(CONTENT_PATH,  '{}_sample_recommender.pkl'.format(VIS_METHOD)), 'wb') as f:\n",
    "    pickle.dump(tm, f, pickle.HIGHEST_PROTOCOL)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open(os.path.join(CONTENT_PATH,  '{}_sample_recommender.pkl'.format(VIS_METHOD)), 'rb') as f:\n",
    "    tm = pickle.load(f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "def add_noise(rate, acc_idxs, rej_idxs):\n",
    "    if rate == 0:\n",
    "        return acc_idxs, rej_idxs\n",
    "    acc_noise = np.random.choice(len(acc_idxs), size=int(len(acc_idxs)*rate))\n",
    "    acc_noise = acc_idxs[acc_noise]\n",
    "    new_acc = np.setdiff1d(acc_idxs, acc_noise)\n",
    "\n",
    "    rej_noise = np.random.choice(len(rej_idxs), size=int(len(rej_idxs)*rate))\n",
    "    rej_noise = rej_idxs[rej_noise]\n",
    "    new_rej = np.setdiff1d(rej_idxs, rej_noise)\n",
    "\n",
    "    new_acc = np.concatenate((new_acc, rej_noise), axis=0)\n",
    "    new_rej = np.concatenate((new_rej, acc_noise), axis=0)\n",
    "    return new_acc, new_rej\n",
    "\n",
    "\n",
    "def init_sampling(tm, method, round, budget, ulb_wrong):\n",
    "    print(\"Feedback sampling initialization ({}):\".format(method))\n",
    "    rate = list()\n",
    "    for _ in range(round):\n",
    "        correct = np.array([]).astype(np.int32)\n",
    "        wrong = np.array([]).astype(np.int32)\n",
    "        \n",
    "        suggest_idxs, _ = tm.sample_batch_init(correct, wrong, budget)\n",
    "        suggest_idxs = ulb_idxs[suggest_idxs]\n",
    "        correct = np.intersect1d(suggest_idxs, ulb_wrong)\n",
    "        rate.append(len(correct)/budget)\n",
    "    print(\"Init success Rate:\\t{:.4f}\".format(sum(rate)/len(rate)))\n",
    "    return sum(rate)/len(rate)\n",
    "\n",
    "\n",
    "def feedback_sampling(tm, method, round, budget, ulb_wrong, noise_rate=0):\n",
    "    print(\"Feedback sampling ({}) with noise rate {}:\".format(method, noise_rate))\n",
    "    rate = np.zeros(round)\n",
    "    correct = np.array([]).astype(np.int32)\n",
    "    wrong = np.array([]).astype(np.int32)\n",
    "    map_ulb =ulb_idxs.tolist()\n",
    "\n",
    "    map_acc_idxs = np.array([map_ulb.index(i) for i in correct]).astype(np.int32)\n",
    "    map_rej_idxs = np.array([map_ulb.index(i) for i in wrong]).astype(np.int32)\n",
    "    suggest_idxs, _ = tm.sample_batch_init(map_acc_idxs, map_rej_idxs, budget)\n",
    "    suggest_idxs = ulb_idxs[suggest_idxs]\n",
    "    correct = np.intersect1d(suggest_idxs, ulb_wrong)\n",
    "    wrong = np.setdiff1d(suggest_idxs, correct)\n",
    "    rate[0] = len(correct)/budget\n",
    "    # inject noise\n",
    "    correct, wrong = add_noise(noise_rate, correct, wrong)\n",
    "    for r in range(1, round):\n",
    "        map_acc_idxs = np.array([map_ulb.index(i) for i in correct]).astype(np.int32)\n",
    "        map_rej_idxs = np.array([map_ulb.index(i) for i in wrong]).astype(np.int32)\n",
    "        suggest_idxs,_,coef_ = tm.sample_batch(map_acc_idxs, map_rej_idxs, budget, True)\n",
    "        suggest_idxs = ulb_idxs[suggest_idxs]\n",
    "\n",
    "        c = np.intersect1d(np.intersect1d(suggest_idxs, ulb_idxs), ulb_wrong)\n",
    "        w = np.setdiff1d(suggest_idxs, c)\n",
    "        rate[r] = len(c) / budget\n",
    "\n",
    "        # inject noise\n",
    "        c, w = add_noise(noise_rate, c, w)\n",
    "        correct = np.concatenate((correct, c), axis=0)\n",
    "        wrong = np.concatenate((wrong, w), axis=0)\n",
    "    print(\"Success Rate:\\t{:.4f}\".format(sum(rate)/len(rate)))\n",
    "    ac_rate = np.array([rate[:i].mean() for i in range(1, len(rate)+1)])\n",
    "    print(\"Feature Importance: {}\".format(coef_))\n",
    "    return ac_rate"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "# meta info\n",
    "lb_idxs = data_provider.get_labeled_idx(EPOCH_END)\n",
    "ulb_idxs = data_provider.get_unlabeled_idx(LEN, lb_idxs)\n",
    "\n",
    "data = data_provider.train_representation_all(EPOCH_END)\n",
    "labels = data_provider.train_labels_all(EPOCH_END)\n",
    "pred = data_provider.get_pred(EPOCH_END, data).argmax(1)\n",
    "wrong_pred_idx = np.argwhere(pred!=labels).squeeze()\n",
    "ulb_wrong = np.intersect1d(wrong_pred_idx, ulb_idxs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "# get hyperparameters\n",
    "BUDGET = 50\n",
    "TOLERANCE = 0.1\n",
    "ROUND = 10\n",
    "INIT_ROUND = 10000"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "# random init\n",
    "print(\"Random sampling init\")\n",
    "random_rate = list()\n",
    "pool = np.array(ulb_idxs)\n",
    "for _ in range(INIT_ROUND):\n",
    "    s_idxs = np.random.choice(pool,size=BUDGET,replace=False)\n",
    "    random_rate.append(len(np.intersect1d(s_idxs, ulb_wrong))/BUDGET)\n",
    "print(\"Success Rate:\\t{:.4f}\".format(sum(random_rate)/len(random_rate)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "# init\n",
    "init_sampling(tm=tm, method=VIS_METHOD, round=INIT_ROUND, budget=BUDGET, ulb_wrong=ulb_wrong)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "# random sampling\n",
    "print(\"Random sampling feedback:\")\n",
    "random_rate = list()\n",
    "pool = np.array(ulb_idxs)\n",
    "for _ in range(ROUND):\n",
    "    s_idxs = np.random.choice(pool,size=BUDGET,replace=False)\n",
    "    random_rate.append(len(np.intersect1d(s_idxs, ulb_wrong))/BUDGET)\n",
    "    pool = np.setdiff1d(pool, s_idxs)\n",
    "print(\"Success Rate:\\t{:.4f}\".format(sum(random_rate)/len(random_rate)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "# sampling\n",
    "feedback_sampling(tm=tm, method=VIS_METHOD, round=ROUND, budget=BUDGET, ulb_wrong=ulb_wrong, noise_rate=0.0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "# noise tolerance\n",
    "feedback_sampling(tm=tm, method=VIS_METHOD, round=ROUND, budget=BUDGET, ulb_wrong=ulb_wrong, noise_rate=.05)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('SV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa7a9f36e1a1e240450dbe9cc8f6d8df1d5301f36681fb271c44fdd883236b60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
