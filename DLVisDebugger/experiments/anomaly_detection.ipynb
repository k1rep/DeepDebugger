{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "dataset = \"fmnist\"\n",
    "noise_type = \"symmetric\"\n",
    "noise_rate = \"5\"\n",
    "batch_size = 50\n",
    "VIS_METHOD = \"TimeVis\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import time\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.data import NormalDataProvider\n",
    "from singleVis.eval.evaluator import Evaluator\n",
    "from singleVis.projector import Projector, tfDVIProjector, TimeVisProjector"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "inject_OOD = {\n",
    "    \"mnist\":\"cifar10\",\n",
    "    \"fmnist\":\"mnist\",\n",
    "    \"cifar10\":\"mnist\"\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "# tensorflow\n",
    "visible_device = \"0,1,2,3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = visible_device"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "CONTENT_PATH = \"/home/xianglin/projects/DVI_data/noisy/{}/{}/{}/\".format(noise_type, dataset, noise_rate)\n",
    "sys.path.append(CONTENT_PATH)\n",
    "with open(os.path.join(CONTENT_PATH, \"config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = config[VIS_METHOD]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "CLASSES = config[\"CLASSES\"]\n",
    "GPU_ID = config[\"GPU\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "ENCODER_DIMS = VISUALIZATION_PARAMETER[\"ENCODER_DIMS\"]\n",
    "DECODER_DIMS = VISUALIZATION_PARAMETER[\"DECODER_DIMS\"]\n",
    "VIS_MODEL_NAME = VISUALIZATION_PARAMETER[\"VIS_MODEL_NAME\"]\n",
    "\n",
    "TOTOAL_EPOCH = (EPOCH_END-EPOCH_START)//EPOCH_PERIOD + 1\n",
    "\n",
    "# define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import Model.model as subject_model\n",
    "# net = resnet18()\n",
    "net = eval(\"subject_model.{}()\".format(NET))\n",
    "\n",
    "data_provider = NormalDataProvider(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, device=DEVICE, classes=CLASSES, epoch_name=\"Epoch\", verbose=1)\n",
    "\n",
    "if VIS_METHOD == \"tfDVI\":\n",
    "    # Define Projector\n",
    "    flag = \"_temporal_id_withoutB\"\n",
    "    projector = tfDVIProjector(CONTENT_PATH, flag=flag)\n",
    "elif VIS_METHOD == \"TimeVis\":\n",
    "    model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "    projector = TimeVisProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, device=DEVICE)\n",
    "elif VIS_METHOD == \"DeepDebugger\":\n",
    "    model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "    SEGMENTS = VISUALIZATION_PARAMETER[\"SEGMENTS\"]\n",
    "    projector = Projector(vis_model=model, content_path=CONTENT_PATH, segments=SEGMENTS, device=DEVICE)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "from singleVis.visualizer import visualizer\n",
    "vis = visualizer(data_provider, projector, 300)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open(os.path.join(CONTENT_PATH,  '{}_sample_recommender.pkl'.format(VIS_METHOD)), 'rb') as f:\n",
    "    tm = pickle.load(f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "# get images\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "if inject_OOD[dataset] == \"mnist\":\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.MNIST('data/', train=True, download=True,\n",
    "                                transform=torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.ToTensor(),\n",
    "                                    torchvision.transforms.Normalize(\n",
    "                                        # (0.1307,), (0.3081,))\n",
    "                                        (0.5,), (0.5,))\n",
    "                                ])),\n",
    "        batch_size=batch_size, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "if inject_OOD[dataset] == \"cifar10\":\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "if inject_OOD[dataset] == \"fmnist\":\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.FashionMNIST('data/', train=True, download=True,\n",
    "                                transform=torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.ToTensor(),\n",
    "                                    torchvision.transforms.Normalize(\n",
    "                                        (0.5,), (0.5,))\n",
    "                                ])),\n",
    "        batch_size=batch_size, shuffle=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     torchvision.datasets.SVHN(\n",
    "#     root='data',\n",
    "#     split='train',\n",
    "#     download=True,\n",
    "#     transform=torchvision.transforms.ToTensor()),\n",
    "#     batch_size=1, shuffle=True)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "detect_anomaly = lambda scores: max(scores)>0.98\n",
    "max_anomaly = lambda scores: (scores[0]>0.99)&(scores[1]>0.99)&(scores[2]>0.99)\n",
    "anomaly_score = lambda scores: sum(scores)/len(scores)\n",
    "min_anomaly = lambda scores: (scores[0]<0.91)&(scores[1]<0.91)&(scores[2]<0.91)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "t_s = time.time()\n",
    "anomaly = 0\n",
    "# true sample\n",
    "samples = np.zeros((TOTOAL_EPOCH, 10000, 512))\n",
    "for i in range(EPOCH_START, EPOCH_END+1, EPOCH_PERIOD):\n",
    "    e = (i-EPOCH_START)//EPOCH_PERIOD\n",
    "    samples[e] = data_provider.test_representation(i)\n",
    "\n",
    "embeddings_2d = np.zeros((TOTOAL_EPOCH, 10000, 2))\n",
    "for e in range(1, TOTOAL_EPOCH+1, 1):\n",
    "    embeddings_2d[e-1] = projector.batch_project(e, samples[e-1])\n",
    "embeddings_2d = np.transpose(embeddings_2d, [1,0,2])\n",
    "\n",
    "tmp = 0\n",
    "for i in range(10000):\n",
    "    scores = tm.score_new_sample(embeddings_2d[i][-tm.period:])\n",
    "    anomaly = anomaly+ detect_anomaly(scores)\n",
    "    print(scores, detect_anomaly(scores))\n",
    "    if tmp<anomaly_score(scores):\n",
    "        tmp = anomaly_score(scores)\n",
    "        xy_limit = (embeddings_2d[i][:, 0].min()-5, embeddings_2d[i][:, 1].min()-5, embeddings_2d[i][:, 0].max()+5, embeddings_2d[i][:, 1].max()+5)\n",
    "        vis.savefig_trajectory(15, embeddings_2d[i][:, 0], embeddings_2d[i][:, 1], xy_limit=xy_limit, path=\"./vis_{}\".format(i))\n",
    "        print(i)\n",
    "    if max_anomaly(scores):\n",
    "        break\n",
    "    # if min_anomaly(scores):\n",
    "    #     xy_limit = (embeddings_2d[i][:, 0].min()-5, embeddings_2d[i][:, 1].min()-5, embeddings_2d[i][:, 0].max()+5, embeddings_2d[i][:, 1].max()+5)\n",
    "    #     vis.savefig_trajectory(15, embeddings_2d[i][:, 0], embeddings_2d[i][:, 1], xy_limit=xy_limit, path=\"./vis_normal_{}\".format(i))\n",
    "t_e = time.time()\n",
    "print(anomaly/batch_size, round(t_e-t_s, 2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "# # mixup\n",
    "# t_s = time.time()\n",
    "# anomaly = 0\n",
    "\n",
    "# samples = np.zeros((TOTOAL_EPOCH, LEN, 512))\n",
    "# for i in range(EPOCH_START, EPOCH_END, EPOCH_PERIOD):\n",
    "#     e = (i-EPOCH_START)//EPOCH_PERIOD\n",
    "#     samples[e] = data_provider.train_representation(i)\n",
    "# labels = data_provider.train_labels(20)\n",
    "\n",
    "# for i in range(50):\n",
    "#     while True:\n",
    "#         idx1, idx2 = np.random.choice(LEN, 2, replace=False)\n",
    "#         if labels[idx1]!=labels[idx2]:\n",
    "#             break\n",
    "\n",
    "#     mixup = 0.5*samples[:,idx1,:]+0.5*samples[:,idx2,:]+0.5\n",
    "#     embedding_2d = np.zeros((TOTOAL_EPOCH,2))\n",
    "#     for e in range(1, TOTOAL_EPOCH+1, 1):\n",
    "#         embedding_2d[e-1] = projector.batch_project(e, mixup[np.newaxis,e-1])[0]\n",
    "#     scores = tm.score_new_sample(embedding_2d[-tm.period:])\n",
    "#     anomaly = anomaly+ detect_anomaly(scores)\n",
    "#     print(scores, detect_anomaly(scores))\n",
    "\n",
    "# t_e = time.time()\n",
    "# print(anomaly/50, round(t_e-t_s, 2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "# OOD\n",
    "anomaly = 0\n",
    "tmp = 10\n",
    "t_s = time.time()\n",
    "for batch, (img, target) in enumerate(train_loader):\n",
    "    image = img.detach().cpu().numpy()\n",
    "    if dataset == \"mnist\":\n",
    "        image = image[:, :1, :28,:28]\n",
    "    if dataset == \"cifar10\":\n",
    "        image = np.pad(image, ((0,0),(1,1), (2, 2), (2, 2)), 'edge')\n",
    "        # pass\n",
    "    embedding_2d = np.zeros((TOTOAL_EPOCH, batch_size, 2))\n",
    "    for i in range(EPOCH_START, EPOCH_END+1, EPOCH_PERIOD):\n",
    "        e = int((i-EPOCH_START)/EPOCH_PERIOD)\n",
    "        repr = data_provider.feature_function(i)(torch.from_numpy(image).to(DEVICE))\n",
    "        embedding_2d[e] = projector.batch_project(i, repr.detach().cpu().numpy())\n",
    "    embedding_2d = np.transpose(embedding_2d, [1,0,2])\n",
    "    for i in range(batch_size):\n",
    "        scores, idxs = tm.score_new_sample(embedding_2d[i][-tm.period:], True)\n",
    "        anomaly = anomaly+ detect_anomaly(scores)\n",
    "        print(scores, max_anomaly(scores))\n",
    "        # if max_anomaly(scores):\n",
    "        #     xy_limit = (embedding_2d[i][:, 0].min()-5, embedding_2d[i][:, 1].min()-5, embedding_2d[i][:, 0].max()+5, embedding_2d[i][:, 1].max()+5)\n",
    "        #     vis.savefig_trajectory(15, embedding_2d[i][:, 0], embedding_2d[i][:, 1], xy_limit=xy_limit, path=\"./vis\")\n",
    "        if tmp>anomaly_score(scores):\n",
    "            tmp = anomaly_score(scores)\n",
    "            xy_limit = (embedding_2d[i][:, 0].min()-5, embedding_2d[i][:, 1].min()-5, embedding_2d[i][:, 0].max()+5, embedding_2d[i][:, 1].max()+5)\n",
    "            vis.savefig_trajectory(50, embedding_2d[i][:, 0], embedding_2d[i][:, 1], xy_limit=xy_limit, path=\"./ood_{}_{}_{}\".format(batch, i, idxs))\n",
    "t_e = time.time()\n",
    "print(anomaly/batch_size, round(t_e-t_s, 2))\n",
    "    "
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa7a9f36e1a1e240450dbe9cc8f6d8df1d5301f36681fb271c44fdd883236b60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
