{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"symmetric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/xianglin/data/noisy/{}/embedding.npy\".format(dataset)\n",
    "embeddings = np.load(path)\n",
    "\n",
    "path = \"/home/xianglin/data/noisy/{}/clean_label.json\".format(dataset)\n",
    "with open(path, \"r\") as f:\n",
    "    clean_label = json.load(f)\n",
    "path = \"/home/xianglin/data/noisy/{}/noisy_label.json\".format(dataset)\n",
    "with open(path, \"r\") as f:\n",
    "    noisy_label = json.load(f)\n",
    "\n",
    "clean_label = np.array(clean_label)\n",
    "noisy_label = np.array(noisy_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xianglin/miniconda3/envs/timevis/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "sys.path.append(\"/home/xianglin/git_space/DLVisDebugger\")\n",
    "from singleVis.SingleVisualizationModel import SingleVisualizationModel\n",
    "from singleVis.data import NormalDataProvider\n",
    "from singleVis.eval.evaluator import Evaluator\n",
    "from singleVis.projector import Projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_PATH = \"/home/xianglin/data/noisy/symmetric\"\n",
    "sys.path.append(CONTENT_PATH)\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initialization...\n"
     ]
    }
   ],
   "source": [
    "GPU_ID = 0\n",
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "PREPROCESS = config[\"VISUALIZATION\"][\"PREPROCESS\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "LAMBDA = VISUALIZATION_PARAMETER[\"LAMBDA\"]\n",
    "S_LAMBDA = VISUALIZATION_PARAMETER[\"S_LAMBDA\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "INIT_NUM = VISUALIZATION_PARAMETER[\"INIT_NUM\"]\n",
    "ALPHA = VISUALIZATION_PARAMETER[\"ALPHA\"]\n",
    "BETA = VISUALIZATION_PARAMETER[\"BETA\"]\n",
    "MAX_HAUSDORFF = VISUALIZATION_PARAMETER[\"MAX_HAUSDORFF\"]\n",
    "HIDDEN_LAYER = VISUALIZATION_PARAMETER[\"HIDDEN_LAYER\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "T_N_EPOCHS = VISUALIZATION_PARAMETER[\"T_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "SEGMENTS = VISUALIZATION_PARAMETER[\"SEGMENTS\"]\n",
    "RESUME_SEG = VISUALIZATION_PARAMETER[\"RESUME_SEG\"]\n",
    "# define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "content_path = CONTENT_PATH\n",
    "sys.path.append(content_path)\n",
    "\n",
    "import Model.model as subject_model\n",
    "# net = resnet18()\n",
    "net = eval(\"subject_model.{}()\".format(NET))\n",
    "classes = (\"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "data_provider = NormalDataProvider(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, split=-1, device=DEVICE, classes=CLASSES,verbose=1)\n",
    "if PREPROCESS:\n",
    "    data_provider.initialize(LEN//10, l_bound=L_BOUND)\n",
    "\n",
    "model = SingleVisualizationModel(input_dims=512, output_dims=2, units=256, hidden_layer=HIDDEN_LAYER)\n",
    "projector = Projector(vis_model=model, content_path=CONTENT_PATH, segments=SEGMENTS, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 439.56it/s]\n"
     ]
    }
   ],
   "source": [
    "data = data_provider.train_representation(200)\n",
    "pred = data_provider.get_pred(200, data)\n",
    "predictions = pred.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"pairflip\"\n",
    "path = \"/home/xianglin/projects/DVI_data/resnet18_cifar10/embedding.npy\"\n",
    "embeddings = np.load(path)\n",
    "path = \"/home/xianglin/projects/DVI_data/noisy/{}/cifar10/clean_label.json\".format(dataset)\n",
    "with open(path, \"r\") as f:\n",
    "    clean_label = json.load(f)\n",
    "    \n",
    "clean_label = np.array(clean_label)\n",
    "noisy_label = np.copy(clean_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 200, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embeddings.reshape(50000,-1,2)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings[:,80:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 119, 2), (50000, 118, 2))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = embeddings[:,1:,:]-embeddings[:,:-1,:]\n",
    "a = v[:,1:,:]-v[:,:-1,:]\n",
    "v.shape, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Birch(n_clusters=30)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import Birch\n",
    "brc = Birch(n_clusters=30)\n",
    "brc.fit(a.reshape(50000, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 30\n",
    "gt = np.argwhere(noisy_label!=clean_label).squeeze()\n",
    "rates = np.zeros(c)\n",
    "wrong = np.zeros(c)\n",
    "sel = np.zeros(c)\n",
    "for suspect in range(c):\n",
    "    selected_idxs = np.argwhere(brc.labels_==suspect).squeeze()\n",
    "    wrong[suspect] = len(np.intersect1d(selected_idxs, gt))\n",
    "    sel[suspect] = len(selected_idxs)\n",
    "    rates[suspect] = len(np.intersect1d(selected_idxs, gt))/len(selected_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.493 \t 414 / 840\n",
      "0.481 \t 235 / 489\n",
      "0.423 \t 263 / 622\n",
      "0.39 \t 99 / 254\n",
      "0.383 \t 70 / 183\n",
      "0.316 \t 279 / 883\n",
      "0.3 \t 159 / 530\n",
      "0.299 \t 408 / 1365\n",
      "0.269 \t 98 / 364\n",
      "0.269 \t 175 / 651\n",
      "0.267 \t 236 / 883\n",
      "0.26 \t 368 / 1414\n",
      "0.255 \t 208 / 817\n",
      "0.242 \t 145 / 599\n",
      "0.236 \t 213 / 903\n",
      "0.212 \t 155 / 730\n",
      "0.207 \t 150 / 725\n",
      "0.198 \t 264 / 1334\n",
      "0.197 \t 378 / 1915\n",
      "0.193 \t 180 / 935\n",
      "0.187 \t 117 / 626\n",
      "0.173 \t 4225 / 24449\n",
      "0.16 \t 92 / 576\n",
      "0.151 \t 322 / 2132\n",
      "0.14 \t 221 / 1574\n",
      "0.122 \t 92 / 755\n",
      "0.122 \t 47 / 386\n",
      "0.111 \t 257 / 2312\n",
      "0.105 \t 44 / 418\n",
      "0.089 \t 30 / 336\n"
     ]
    }
   ],
   "source": [
    "ranking = np.argsort(rates)\n",
    "for r in range(c-1,-1,-1):\n",
    "    print(round(rates[ranking[r]], 3),\"\\t\", int(wrong[ranking[r]]),\"/\", int(sel[ranking[r]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = brc.labels_\n",
    "suspect = np.argmin(np.bincount(predict_labels))\n",
    "selected_idxs = np.argwhere(predictions==suspect).squeeze()\n",
    "gt = np.argwhere(noisy_label!=clean_label).squeeze()\n",
    "len(np.intersect1d(selected_idxs, gt)), len(selected_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Birch(n_clusters=20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brc = Birch(n_clusters=20)\n",
    "brc.fit(v.reshape(50000, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 257)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_labels = brc.labels_\n",
    "suspect = np.argmin(np.bincount(predict_labels))\n",
    "selected_idxs = np.argwhere(brc.labels_==suspect).squeeze()\n",
    "gt = np.argwhere(noisy_label!=clean_label).squeeze()\n",
    "len(np.intersect1d(selected_idxs, gt)), len(selected_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Birch(n_clusters=20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brc = Birch(n_clusters=20)\n",
    "data = np.concatenate((a.reshape(50000, -1), v.reshape(50000,-1)), axis=1)\n",
    "brc.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 328)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_labels = brc.labels_\n",
    "suspect = np.argmin(np.bincount(predict_labels))\n",
    "selected_idxs = np.argwhere(brc.labels_==suspect).squeeze()\n",
    "gt = np.argwhere(noisy_label!=clean_label).squeeze()\n",
    "len(np.intersect1d(selected_idxs, gt)), len(selected_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from noise_detector import NoiseTrajectoryDetector\n",
    "ntd = NoiseTrajectoryDetector(embeddings, noisy_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls_num=2\n",
    "# ntd.proj_cls(cls_num, period=75, repeat=2)\n",
    "ntd.proj_all(period=75) # 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls_num in range(10):\n",
    "    # print(cls_num, ntd.detect_noise_cls(cls_num))\n",
    "    best_s, best_c = ntd.trajectory_eval[str(cls_num)]\n",
    "    print(\"silhouette_score\\t\", best_s)\n",
    "    print(\"calinski_harabasz_score\\t\", best_c)\n",
    "    flag = best_c>.5\n",
    "\n",
    "    print(cls_num, flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls_num in range(10):\n",
    "    # print(cls_num, ntd.detect_noise_cls(cls_num))\n",
    "    best_s, best_c = ntd.trajectory_eval[str(cls_num)]\n",
    "    print(\"silhouette_score\\t\", best_s)\n",
    "    print(\"calinski_harabasz_score\\t\", best_c)\n",
    "    flag = best_c>.5\n",
    "    print(cls_num, flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(10):\n",
    "    ntd.show_ground_truth(num,clean_label[noisy_label==num])\n",
    "    ntd.show_scores(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(10):\n",
    "    ntd.show_ground_truth(num,clean_label[noisy_label==num])\n",
    "    ntd.show_scores(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from noise_detector import select_closest\n",
    "import math\n",
    "\n",
    "for num in range(10):\n",
    "    print(\"=================================={}=========================================\".format(num))\n",
    "    clean_labels = clean_label[noisy_label==num]\n",
    "    ntd.show_ground_truth(num,clean_labels)\n",
    "\n",
    "    c = ntd.sub_centers[str(num)]\n",
    "    embedding = ntd.trajectory_embedding[str(num)]\n",
    "    centroids = embedding[c]\n",
    "\n",
    "    # vote for labels and scores\n",
    "    c_labels = select_closest(embedding, centroids)\n",
    "    centroid_labels = np.zeros(len(centroids))\n",
    "    for i in range(len(centroids)):\n",
    "        centroid_labels[i] = np.bincount(clean_labels[c_labels==i]).argmax()\n",
    "\n",
    "    gt = centroid_labels\n",
    "    nt = np.sum(gt!=num)\n",
    "    ct = len(c) - nt\n",
    "\n",
    "    curr_nt = nt\n",
    "    flag = math.floor(nt*0.9)\n",
    "    target_flag = flag\n",
    "\n",
    "    for t in range(len(c)):\n",
    "        id, _, selected = ntd.suggest_abnormal(num)\n",
    "        d = False\n",
    "        # if clean_label[noisy_label==num][id] != num:ß\n",
    "        if gt[id] != num:\n",
    "            d = True\n",
    "            flag=flag-1\n",
    "            curr_nt=curr_nt-1\n",
    "        ntd.update_belief(num, selected, d)\n",
    "        # ntd.show_verified(num)\n",
    "        if flag==0:\n",
    "            print(\"[{}]\\t{} rounds find {} (90%) noise samples\".format(target_flag/(t+1), t+1, target_flag))\n",
    "            flag=10000\n",
    "        if curr_nt==0:\n",
    "            print(\"[{}]\\t{} rounds find all {} noise samples\".format(nt/(t+1), t+1, len(c)-ct))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from noise_detector import select_closest\n",
    "import math\n",
    "\n",
    "# Ground Truth\n",
    "for num in range(10):\n",
    "    print(\"=================================={}=========================================\".format(num))\n",
    "    clean_labels = clean_label[noisy_label==num]\n",
    "    ntd.show_ground_truth(num,clean_labels)\n",
    "\n",
    "    c = ntd.sub_centers[str(num)]\n",
    "    embedding = ntd.trajectory_embedding[str(num)]\n",
    "    centroids = embedding[c]\n",
    "\n",
    "    # vote for labels and scores\n",
    "    c_labels = select_closest(embedding, centroids)\n",
    "    centroid_labels = np.zeros(len(centroids))\n",
    "    for i in range(len(centroids)):\n",
    "        centroid_labels[i] = np.bincount(clean_labels[c_labels==i]).argmax()\n",
    "\n",
    "    gt = centroid_labels\n",
    "    nt = np.sum(gt!=num)\n",
    "    ct = len(c) - nt\n",
    "\n",
    "    curr_nt = nt\n",
    "    flag = math.floor(nt*0.9)\n",
    "    target_flag = flag\n",
    "\n",
    "    candidate_list = np.arange(len(c)).tolist()\n",
    "\n",
    "    for t in range(len(c)):\n",
    "        # id, _, selected = ntd.suggest_abnormal(num)\n",
    "        id = np.random.choice(candidate_list,1)[0]\n",
    "        selected = centroids[id]\n",
    "        candidate_list.remove(id)\n",
    "        d = False\n",
    "        # if clean_label[noisy_label==num][id] != num:\n",
    "        if gt[id] != num:\n",
    "            d = True\n",
    "            flag=flag-1\n",
    "            curr_nt=curr_nt-1\n",
    "        ntd.update_belief(num, selected, d)\n",
    "        if flag==0:\n",
    "            print(\"[{}]\\t{} rounds find {} (90%) noise samples\".format(target_flag/(t+1), t+1, target_flag))\n",
    "            flag=10000\n",
    "        if curr_nt==0:\n",
    "            print(\"[{}]\\t{} rounds find all {} noise samples\".format(nt/(t+1), t+1, len(c)-ct))\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('timevis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee9d2b45af2f0386ad86dea8873e1fdf9843516f676ff1d447c55abb6a82f45d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
