{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.data import NormalDataProvider\n",
    "from singleVis.eval.evaluator import Evaluator\n",
    "from singleVis.projector import Projector, tfDVIProjector, TimeVisProjector"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "# tensorflow\n",
    "visible_device = \"0,1,2,3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = visible_device"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "dataset = \"cifar10\"\n",
    "noise_type = \"symmetric\"\n",
    "noise_rate = \"5\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "path = \"/home/xianglin/projects/DVI_data/noisy/{}/{}/{}/clean_label.json\".format(noise_type, dataset, noise_rate)\n",
    "with open(path, \"r\") as f:\n",
    "    clean_label = json.load(f)\n",
    "path = \"/home/xianglin/projects/DVI_data/noisy/{}/{}/{}/noisy_label.json\".format(noise_type, dataset, noise_rate)\n",
    "with open(path, \"r\") as f:\n",
    "    noisy_label = json.load(f)\n",
    "\n",
    "clean_label = np.array(clean_label)\n",
    "noisy_label = np.array(noisy_label)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "VIS_METHOD = \"TimeVis\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "CONTENT_PATH = \"/home/xianglin/projects/DVI_data/noisy/{}/{}/{}/\".format(noise_type, dataset, noise_rate)\n",
    "sys.path.append(CONTENT_PATH)\n",
    "with open(os.path.join(CONTENT_PATH, \"config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = config[VIS_METHOD]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "CLASSES = config[\"CLASSES\"]\n",
    "GPU_ID = config[\"GPU\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "ENCODER_DIMS = VISUALIZATION_PARAMETER[\"ENCODER_DIMS\"]\n",
    "DECODER_DIMS = VISUALIZATION_PARAMETER[\"DECODER_DIMS\"]\n",
    "VIS_MODEL_NAME = VISUALIZATION_PARAMETER[\"VIS_MODEL_NAME\"]\n",
    "\n",
    "TOTOAL_EPOCH = (EPOCH_END-EPOCH_START)//EPOCH_PERIOD + 1\n",
    "\n",
    "# define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import Model.model as subject_model\n",
    "# net = resnet18()\n",
    "net = eval(\"subject_model.{}()\".format(NET))\n",
    "\n",
    "data_provider = NormalDataProvider(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, device=DEVICE, classes=CLASSES, epoch_name=\"Epoch\", verbose=1)\n",
    "\n",
    "if VIS_METHOD == \"tfDVI\":\n",
    "    # Define Projector\n",
    "    flag = \"_temporal_id_withoutB\"\n",
    "    projector = tfDVIProjector(CONTENT_PATH, flag=flag)\n",
    "elif VIS_METHOD == \"TimeVis\":\n",
    "    model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "    projector = TimeVisProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, device=DEVICE)\n",
    "elif VIS_METHOD == \"DeepDebugger\":\n",
    "    model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "    SEGMENTS = VISUALIZATION_PARAMETER[\"SEGMENTS\"]\n",
    "    projector = Projector(vis_model=model, content_path=CONTENT_PATH, segments=SEGMENTS, device=DEVICE)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "samples = np.zeros((TOTOAL_EPOCH, 100, 512))\n",
    "for i in range(EPOCH_START, EPOCH_END, EPOCH_PERIOD):\n",
    "    e = (i-EPOCH_START)//EPOCH_PERIOD\n",
    "    samples[e] = data_provider.test_representation(i)[:100]\n",
    "\n",
    "embeddings_2d = np.zeros((TOTOAL_EPOCH, 100, 2))\n",
    "for e in range(1, TOTOAL_EPOCH+1, 1):\n",
    "    embeddings_2d[e-1] = projector.batch_project(e, samples[e-1])\n",
    "embeddings_2d = np.transpose(embeddings_2d, [1,0,2])\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "# samples = np.zeros((TOTOAL_EPOCH, LEN, 512))\n",
    "# for i in range(EPOCH_START, EPOCH_END, EPOCH_PERIOD):\n",
    "#     e = (i-EPOCH_START)//EPOCH_PERIOD\n",
    "#     samples[e] = data_provider.train_representation(i)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "# # embeddings_2d = np.zeros((TOTOAL_EPOCH, LEN, 2))\n",
    "# # for e in range(1, TOTOAL_EPOCH+1, 1):\n",
    "# #     embeddings_2d[e-1] = projector.batch_project(e, samples[e-1])\n",
    "# # embeddings_2d = np.transpose(embeddings_2d, [1,0,2])\n",
    "\n",
    "# embeddings_2d = np.zeros((TOTOAL_EPOCH, LEN, 2))\n",
    "# for i in range(EPOCH_START, EPOCH_END, EPOCH_PERIOD):\n",
    "#     e = (i-EPOCH_START)//EPOCH_PERIOD\n",
    "#     embeddings_2d[e] = projector.batch_project(i, samples[e])\n",
    "# embeddings_2d = np.transpose(embeddings_2d, [1,0,2])\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "# path = os.path.join(CONTENT_PATH, \"Model\",\"{}_trajectory_embeddings.npy\".format(VIS_METHOD))\n",
    "# np.save(path,embeddings_2d)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "# path = os.path.join(CONTENT_PATH, \"Model\",\"{}_trajectory_embeddings.npy\".format(VIS_METHOD))\n",
    "# embeddings_2d = np.load(path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "# from scipy.special import softmax\n",
    "# samples = data_provider.train_representation(TOTOAL_EPOCH)\n",
    "# pred = data_provider.get_pred(TOTOAL_EPOCH, samples)\n",
    "# confidence = np.amax(softmax(pred, axis=1), axis=1)\n",
    "# uncertainty = 1-confidence\n",
    "# uncertainty.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "# noise_idxs = np.argwhere(clean_label!=noisy_label).squeeze()\n",
    "# noise_idxs.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "# from singleVis.trajectory_manager import Recommender\n",
    "# import pickle\n",
    "# tm = Recommender(uncertainty, embeddings_2d, 30, period=130)\n",
    "# tm.clustered()\n",
    "# with open(os.path.join(CONTENT_PATH,  '{}_sample_recommender.pkl'.format(VIS_METHOD)), 'wb') as f:\n",
    "#     pickle.dump(tm, f, pickle.HIGHEST_PROTOCOL)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open(os.path.join(CONTENT_PATH,  '{}_sample_recommender.pkl'.format(VIS_METHOD)), 'rb') as f:\n",
    "    tm = pickle.load(f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "BUDGET = 50\n",
    "TOLERANCE = 0.1\n",
    "ROUND = 10\n",
    "INIT_ROUND = 10000"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "def add_noise(rate, acc_idxs, rej_idxs):\n",
    "    if rate == 0:\n",
    "        return acc_idxs, rej_idxs\n",
    "    acc_noise = np.random.choice(len(acc_idxs), size=int(len(acc_idxs)*rate))\n",
    "    acc_noise = acc_idxs[acc_noise]\n",
    "    new_acc = np.setdiff1d(acc_idxs, acc_noise)\n",
    "\n",
    "    rej_noise = np.random.choice(len(rej_idxs), size=int(len(rej_idxs)*rate))\n",
    "    rej_noise = rej_idxs[rej_noise]\n",
    "    new_rej = np.setdiff1d(rej_idxs, rej_noise)\n",
    "\n",
    "    new_acc = np.concatenate((new_acc, rej_noise), axis=0)\n",
    "    new_rej = np.concatenate((new_rej, acc_noise), axis=0)\n",
    "    return new_acc, new_rej\n",
    "\n",
    "def init_sampling(tm, method, round, budget):\n",
    "    print(\"Feedback sampling initialization ({}):\".format(method))\n",
    "    init_rate = list()\n",
    "    for _ in range(round):\n",
    "        correct = np.array([]).astype(np.int32)\n",
    "        wrong = np.array([]).astype(np.int32)\n",
    "        selected,_ = tm.sample_batch_init(correct, wrong, budget)\n",
    "        c = np.intersect1d(selected, noise_idxs)\n",
    "        init_rate.append(len(c)/budget)\n",
    "    print(\"Success Rate:\\t{:.4f}\".format(sum(init_rate)/len(init_rate)))\n",
    "    return sum(init_rate)/len(init_rate)\n",
    "\n",
    "def feedback_sampling(tm, method, round, budget, noise_rate=0.0):\n",
    "    print(\"Feedback sampling ({}) with noise {}:\".format(method, noise_rate))\n",
    "    rate = np.zeros(round)\n",
    "    correct = np.array([]).astype(np.int32)\n",
    "    wrong = np.array([]).astype(np.int32)\n",
    "    selected,_ = tm.sample_batch_init(correct, wrong, budget)\n",
    "    c = np.intersect1d(selected, noise_idxs)\n",
    "    w = np.setdiff1d(selected, c)\n",
    "    correct = np.concatenate((correct, c), axis=0)\n",
    "    wrong = np.concatenate((wrong, w), axis=0)\n",
    "    rate[0] = len(correct)/float(budget)\n",
    "\n",
    "    # inject noise\n",
    "    correct, wrong = add_noise(noise_rate, correct, wrong)\n",
    "\n",
    "    for r in range(1, round, 1):\n",
    "        selected,_,coef_ = tm.sample_batch(correct, wrong, budget, True)\n",
    "        c = np.intersect1d(selected, noise_idxs)\n",
    "        w = np.setdiff1d(selected, c)\n",
    "        rate[r] = len(c)/budget\n",
    "        # inject noise\n",
    "        c, w = add_noise(noise_rate, c, w)\n",
    "\n",
    "        correct = np.concatenate((correct, c), axis=0)\n",
    "        wrong = np.concatenate((wrong, w), axis=0)\n",
    "    print(\"Success Rate:\\t{:.4f}\".format(rate.mean()))\n",
    "    ac_rate = np.array([rate[:i].mean() for i in range(1, len(rate)+1)])\n",
    "    print(coef_)\n",
    "    return ac_rate"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "from singleVis.utils import generate_random_trajectory_momentum, generate_random_trajectory\n",
    "from singleVis.visualizer import visualizer"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "xs = tm.embeddings_2d[:, :, 0]\n",
    "ys = tm.embeddings_2d[:, :, 1]\n",
    "vx = xs[:, 1:]-xs[:, :-1]\n",
    "vy = ys[:, 1:]-ys[:, :-1]\n",
    "x_min = xs.min()\n",
    "y_min = ys.min()\n",
    "x_max = xs.max()\n",
    "y_max = ys.max()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "idx = np.random.choice(len(xs), 1)[0]\n",
    "init_position = [xs[idx, 0], ys[idx, 0]]\n",
    "vx_mean = vx[idx]\n",
    "vy_mean = vy[idx]\n",
    "new_sample = generate_random_trajectory_momentum(init_position, 200,1,.1, vx_mean, vy_mean)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "vis = visualizer(data_provider, projector, 300)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "xy_limit = (xs[idx].min()-5, ys[idx].min()-5, xs[idx].max()+5, ys[idx].max()+5)\n",
    "print(xy_limit)\n",
    "vis.savefig_trajectory(200, xs[idx][:-1], ys[idx][:-1], xy_limit=xy_limit, path=\"./vis\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "xy_limit = (new_sample[:,0].min()-5, new_sample[:, 1].min()-5, new_sample[:,0].max()+5, new_sample[:, 1].max()+5)\n",
    "print(xy_limit)\n",
    "vis.savefig_trajectory(200, new_sample[:,0], new_sample[:, 1], xy_limit=xy_limit, path=\".\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "tm.score_new_sample(embeddings_2d[1][-tm.period:])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "new_sample = embeddings_2d[1]\n",
    "new_sample[-1,0] = 0\n",
    "new_sample[-1,1] = 0\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# random init\n",
    "print(\"Random sampling init\")\n",
    "s_rate = list()\n",
    "pool = np.arange(LEN)\n",
    "for _ in range(INIT_ROUND):\n",
    "    s_idxs = np.random.choice(pool,size=BUDGET,replace=False)\n",
    "    s_rate.append(len(np.intersect1d(s_idxs, noise_idxs))/BUDGET)\n",
    "print(\"Success Rate:\\t{:.4f}\".format(sum(s_rate)/len(s_rate)))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# dvi init\n",
    "init_sampling(tm, method=VIS_METHOD, round=INIT_ROUND, budget=BUDGET)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# random Feedback\n",
    "print(\"Random sampling feedback\")\n",
    "random_rate = np.zeros(ROUND)\n",
    "pool = np.arange(LEN)\n",
    "for r in range(ROUND):\n",
    "    s_idxs = np.random.choice(pool,size=BUDGET,replace=False)\n",
    "    random_rate[r] = len(np.intersect1d(s_idxs, noise_idxs))/BUDGET\n",
    "    pool = np.setdiff1d(pool, s_idxs)\n",
    "print(\"Success Rate:\\t{:.4f}\".format(sum(random_rate)/len(random_rate)))\n",
    "ac_random_rate = np.array([random_rate[:i].mean() for i in range(1, len(random_rate)+1)])\n",
    "print(ac_random_rate)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# dvi Feedback\n",
    "feedback_sampling(tm=tm, method=VIS_METHOD, round=ROUND, budget=BUDGET)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# dvi Feedback with noise\n",
    "feedback_sampling(tm=tm, method=VIS_METHOD, round=ROUND, budget=BUDGET, noise_rate=TOLERANCE)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('SV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa7a9f36e1a1e240450dbe9cc8f6d8df1d5301f36681fb271c44fdd883236b60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
